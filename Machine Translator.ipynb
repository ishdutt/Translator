{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural machine translation with attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the file\n",
    "path_to_file = os.path.dirname('./')+\"/deu-eng/deu.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " deu-eng   deu-eng.zip\t'Machine Translator.ipynb'\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts the unicode file to ascii\n",
    "def unicode_to_ascii(s):\n",
    "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "      if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "\n",
    "def preprocess_sentence(w):\n",
    "  w = unicode_to_ascii(w.lower().strip())\n",
    "\n",
    "  # creating a space between a word and the punctuation following it\n",
    "  # eg: \"he is a boy.\" => \"he is a boy .\"\n",
    "  # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "  w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "  w = re.sub(r'[\" \"]+', \" \", w)\n",
    "\n",
    "  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "  w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "\n",
    "  w = w.rstrip().strip()\n",
    "\n",
    "  # adding a start and an end token to the sentence\n",
    "  # so that the model know when to start and stop predicting.\n",
    "  w = '<start> ' + w + ' <end>'\n",
    "  return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> hello dear <end>\n",
      "b'<start> hallo schatz <end>'\n"
     ]
    }
   ],
   "source": [
    "# Sample of the above function\n",
    "en_sentence = u\"hello dear\"\n",
    "ger_sentence = u\"Hallo Schatz\"\n",
    "print(preprocess_sentence(en_sentence))\n",
    "print(preprocess_sentence(ger_sentence).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Remove the accents\n",
    "# 2. Clean the sentences\n",
    "# 3. Return word pairs in the format: [ENGLISH, German]\n",
    "def create_dataset(path, num_examples):\n",
    "  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
    "\n",
    "  word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
    "\n",
    "  return zip(*word_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> i recommend contributing sentences in your own native language , since people will be able to trust that what you have contributed is likely to be good and natural sounding . <end>\n",
      "<start> ich empfehle , muttersprachliche satze beizutragen , denn bei diesen kann man auch davon ausgehen , dass sie naturlich klingen . <end>\n"
     ]
    }
   ],
   "source": [
    "en, ger, garbage = create_dataset(path_to_file, None)\n",
    "print(en[-10])\n",
    "print(ger[-10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_length(tensor):\n",
    "  return max(len(t) for t in tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(lang):\n",
    "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "      filters='')\n",
    "  lang_tokenizer.fit_on_texts(lang)\n",
    "\n",
    "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "\n",
    "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
    "                                                         padding='post')\n",
    "\n",
    "  return tensor, lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading Dataset ... 1. Splitting it into Eng Ger\n",
    "                    #2. TOkenize the input language\n",
    "                    #3.TOkenise the target laguage\n",
    "def load_dataset(path, num_examples=None):\n",
    "  # creating cleaned input, output pairs\n",
    "  targ_lang, inp_lang, garbage = create_dataset(path, num_examples)\n",
    "\n",
    "  input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
    "  target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
    "\n",
    "  return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try experimenting with the size of that dataset\n",
    "num_examples = 30000\n",
    "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n",
    "\n",
    "# Calculate max_length of the target tensors\n",
    "max_length_targ, max_length_inp = max_length(target_tensor), max_length(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21000 21000 9000 9000\n"
     ]
    }
   ],
   "source": [
    "# Creating training and validation sets using an 70-30 split\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.3)\n",
    "\n",
    "# Show length\n",
    "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(lang, tensor):\n",
    "  for t in tensor:\n",
    "    if t!=0:\n",
    "      print (\"%d ----> %s\" % (t, lang.index_word[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Language; index to word mapping\n",
      "1 ----> <start>\n",
      "5 ----> ich\n",
      "315 ----> hab\n",
      "9 ----> das\n",
      "105 ----> kommen\n",
      "99 ----> gesehen\n",
      "3 ----> .\n",
      "2 ----> <end>\n",
      "\n",
      "Target Language; index to word mapping\n",
      "1 ----> <start>\n",
      "5 ----> i\n",
      "92 ----> saw\n",
      "22 ----> this\n",
      "172 ----> coming\n",
      "3 ----> .\n",
      "2 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "print (\"Input Language; index to word mapping\")\n",
    "convert(inp_lang, input_tensor_train[0])\n",
    "print ()\n",
    "print (\"Target Language; index to word mapping\")\n",
    "convert(targ_lang, target_tensor_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyper Parameters\n",
    "\n",
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(inp_lang.word_index)+1\n",
    "vocab_tar_size = len(targ_lang.word_index)+1\n",
    "\n",
    "\n",
    "# Creates Dataset taking the tensors as input\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 14]), TensorShape([64, 10]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the encoder and decoder model\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.enc_units = enc_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "\n",
    "  def call(self, x, hidden):\n",
    "    x = self.embedding(x)\n",
    "    output, state = self.gru(x, initial_state = hidden)\n",
    "    return output, state\n",
    "\n",
    "  def initialize_hidden_state(self):\n",
    "    return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (64, 14, 1024)\n",
      "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "# sample input\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, units):\n",
    "    super(BahdanauAttention, self).__init__()\n",
    "    self.W1 = tf.keras.layers.Dense(units)\n",
    "    self.W2 = tf.keras.layers.Dense(units)\n",
    "    self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "  def call(self, query, values):\n",
    "    # hidden shape == (batch_size, hidden size)\n",
    "    # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "    # we are doing this to perform addition to calculate the score\n",
    "    hidden_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "    # score shape == (batch_size, max_length, 1)\n",
    "    # we get 1 at the last axis because we are applying score to self.V\n",
    "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "    score = self.V(tf.nn.tanh(\n",
    "        self.W1(values) + self.W2(hidden_with_time_axis)))\n",
    "\n",
    "    # attention_weights shape == (batch_size, max_length, 1)\n",
    "    attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "    # context_vector shape after sum == (batch_size, hidden_size)\n",
    "    context_vector = attention_weights * values\n",
    "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "    return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) (64, 1024)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (64, 14, 1)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = BahdanauAttention(10)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.dec_units = dec_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    # used for attention\n",
    "    self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "  def call(self, x, hidden, enc_output):\n",
    "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "    x = self.embedding(x)\n",
    "\n",
    "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "    # passing the concatenated vector to the GRU\n",
    "    output, state = self.gru(x)\n",
    "\n",
    "    # output shape == (batch_size * 1, hidden_size)\n",
    "    output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "    # output shape == (batch_size, vocab)\n",
    "    x = self.fc(output)\n",
    "\n",
    "    return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (64, 4557)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "                                      sample_hidden, sample_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the optimizer and the loss function\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "\n",
    "  return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoints (Object-based saving)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "1. Pass the *input* through the *encoder* which return *encoder output* and the *encoder hidden state*.\n",
    "2. The encoder output, encoder hidden state and the decoder input (which is the *start token*) is passed to the decoder.\n",
    "3. The decoder returns the *predictions* and the *decoder hidden state*.\n",
    "4. The decoder hidden state is then passed back into the model and the predictions are used to calculate the loss.\n",
    "5. Use *teacher forcing* to decide the next input to the decoder.\n",
    "6. *Teacher forcing* is the technique where the *target word* is passed as the *next input* to the decoder.\n",
    "7. The final step is to calculate the gradients and apply it to the optimizer and backpropagate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "  loss = 0\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "\n",
    "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "    # Teacher forcing - feeding the target as the next input\n",
    "    for t in range(1, targ.shape[1]):\n",
    "      # passing enc_output to the decoder\n",
    "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "\n",
    "      loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "      # using teacher forcing\n",
    "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "  batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "  gradients = tape.gradient(loss, variables)\n",
    "\n",
    "  optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "  return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 4.5941\n",
      "Epoch 1 Batch 100 Loss 2.1543\n",
      "Epoch 1 Batch 200 Loss 1.8305\n",
      "Epoch 1 Batch 300 Loss 1.6466\n",
      "Epoch 1 Loss 2.0447\n",
      "Time taken for 1 epoch 496.6415967941284 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 1.4745\n",
      "Epoch 2 Batch 100 Loss 1.4509\n",
      "Epoch 2 Batch 200 Loss 1.3916\n",
      "Epoch 2 Batch 300 Loss 1.1795\n",
      "Epoch 2 Loss 1.3523\n",
      "Time taken for 1 epoch 476.41636872291565 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 1.0745\n",
      "Epoch 3 Batch 100 Loss 1.0613\n",
      "Epoch 3 Batch 200 Loss 0.8499\n",
      "Epoch 3 Batch 300 Loss 1.0297\n",
      "Epoch 3 Loss 1.0134\n",
      "Time taken for 1 epoch 473.371408700943 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.7586\n",
      "Epoch 4 Batch 100 Loss 0.7249\n",
      "Epoch 4 Batch 200 Loss 0.7765\n",
      "Epoch 4 Batch 300 Loss 0.6895\n",
      "Epoch 4 Loss 0.7393\n",
      "Time taken for 1 epoch 474.0335702896118 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.4697\n",
      "Epoch 5 Batch 100 Loss 0.4855\n",
      "Epoch 5 Batch 200 Loss 0.4965\n",
      "Epoch 5 Batch 300 Loss 0.4824\n",
      "Epoch 5 Loss 0.5182\n",
      "Time taken for 1 epoch 469.66333961486816 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.3069\n",
      "Epoch 6 Batch 100 Loss 0.3419\n",
      "Epoch 6 Batch 200 Loss 0.3663\n",
      "Epoch 6 Batch 300 Loss 0.3831\n",
      "Epoch 6 Loss 0.3516\n",
      "Time taken for 1 epoch 465.5520577430725 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.1778\n",
      "Epoch 7 Batch 100 Loss 0.1966\n",
      "Epoch 7 Batch 200 Loss 0.2144\n",
      "Epoch 7 Batch 300 Loss 0.2651\n",
      "Epoch 7 Loss 0.2388\n",
      "Time taken for 1 epoch 464.2663550376892 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.1463\n",
      "Epoch 8 Batch 100 Loss 0.1532\n",
      "Epoch 8 Batch 200 Loss 0.1896\n",
      "Epoch 8 Batch 300 Loss 0.1790\n",
      "Epoch 8 Loss 0.1632\n",
      "Time taken for 1 epoch 464.910115480423 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.0828\n",
      "Epoch 9 Batch 100 Loss 0.1671\n",
      "Epoch 9 Batch 200 Loss 0.1184\n",
      "Epoch 9 Batch 300 Loss 0.1751\n",
      "Epoch 9 Loss 0.1213\n",
      "Time taken for 1 epoch 462.2981140613556 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.0702\n",
      "Epoch 10 Batch 100 Loss 0.0846\n",
      "Epoch 10 Batch 200 Loss 0.1159\n",
      "Epoch 10 Batch 300 Loss 0.1013\n",
      "Epoch 10 Loss 0.0953\n",
      "Time taken for 1 epoch 462.41575360298157 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "\n",
    "  enc_hidden = encoder.initialize_hidden_state()\n",
    "  total_loss = 0\n",
    "\n",
    "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "    batch_loss = train_step(inp, targ, enc_hidden)\n",
    "    total_loss += batch_loss\n",
    "\n",
    "    if batch % 100 == 0:\n",
    "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                   batch,\n",
    "                                                   batch_loss.numpy()))\n",
    "  # saving (checkpoint) the model every 2 epochs\n",
    "  if (epoch + 1) % 2 == 0:\n",
    "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate\n",
    "\n",
    "* The evaluate function is similar to the training loop, except we don't use *teacher forcing* here. The input to the decoder at each time step is its previous predictions along with the hidden state and the encoder output.\n",
    "* Stop predicting when the model predicts the *end token*.\n",
    "* And store the *attention weights for every time step*.\n",
    "\n",
    "Note: The encoder output is calculated only once for one input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
    "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                         maxlen=max_length_inp,\n",
    "                                                         padding='post')\n",
    "  inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "  result = ''\n",
    "\n",
    "  hidden = [tf.zeros((1, units))]\n",
    "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "  dec_hidden = enc_hidden\n",
    "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
    "\n",
    "  for t in range(max_length_targ):\n",
    "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                         dec_hidden,\n",
    "                                                         enc_out)\n",
    "\n",
    "    # storing the attention weights to plot later on\n",
    "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "    attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "    result += targ_lang.index_word[predicted_id] + ' '\n",
    "\n",
    "    if targ_lang.index_word[predicted_id] == '<end>':\n",
    "      return result, sentence, attention_plot\n",
    "\n",
    "    # the predicted ID is fed back into the model\n",
    "    dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "  return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for plotting the attention weights\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "  fig = plt.figure(figsize=(10,10))\n",
    "  ax = fig.add_subplot(1, 1, 1)\n",
    "  ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "  fontdict = {'fontsize': 14}\n",
    "\n",
    "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "  result, sentence, attention_plot = evaluate(sentence)\n",
    "\n",
    "  print('Input: %s' % (sentence))\n",
    "  print('Predicted translation: {}'.format(result))\n",
    "\n",
    "  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restore the latest checkpoint and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f499af898d0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restoring the latest checkpoint in checkpoint_dir\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> das bin ich <end>\n",
      "Predicted translation: that s how i am . <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(u'Das bin ich')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
